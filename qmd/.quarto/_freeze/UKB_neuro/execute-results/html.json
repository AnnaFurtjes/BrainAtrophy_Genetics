{
  "hash": "6aefdd0f2469b5add882a0e22c173cdd",
  "result": {
    "markdown": "---\ntitle: \"UK Biobank: Neuroimaging data preparation\"\nformat: \n  html:\n    code-fold: true\nauthor: \"Anna Elisabeth Furtjes\"\ndate: \"01 November 2024\"\noutput: html\ndoi: test\n---\n\n\n------------------------------------------------------------------------\n\n\n\n\n\nCode displayed here was used to obtain neuroimaging measures: TBV, ICV, LBA (difference, ratio, residual scores).\n\n\n## Load packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(ggpubr)\nlibrary(cowplot)\n```\n:::\n\n\n## Define functions\n\nFunctions `plot_hist` and descriptives expect input data set to contain variables called diff, ratio, resid. `plot_hist` can also handle diff_stand, ratio_stand, resid_stand and will add an extra x-axis if input are standardised variables.\n\n`descriptives` gives a table of descriptive statistics for TBV, ICV and LBA phenotypes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_hist <- function(dat = dat, var = \"diff_stand\", split_sample_by = NULL){\n  # install packages if they don't already exits\n  packages = c(\"ggplot2\",\"stringr\", \"tidyr\", \"dplyr\")\n  install.packages(setdiff(packages, rownames(installed.packages())))\n  # load packages\n  library(ggplot2)\n  library(stringr)\n  library(tidyr)\n  library(dplyr)\n\n  # make sure input data is data.frame\n  dat = as.data.frame(dat)\n  # rename for simplicity\n  dat$var = dat[,var]\n\n  # calculate summary stats\n    df_stats <-\n        dat %>%\n        summarize(\n          mean = mean(var, na.rm=T),\n          median = median(var, na.rm=T)\n        ) %>%\n        gather(key = Statistic, value = value, mean:median)\n\n    # calculate SD cutoffs\n    insert = c(\"+2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) + 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    insert = c(\"-2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) - 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    # format\n    df_stats$value <- as.numeric(df_stats$value)\n\n    # consider one-sided nature of cut-off\n    # if difference score, we use the upper 2 SD limit\n    # if ratio or residual score, we use the lower 2 SD limit\n    if(var == \"diff\" | var == \"diff_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"-2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }else if(var == \"ratio\" | var == \"resid\" | var == \"ratio_stand\" | var == \"resid_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"+2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }\n\n\n  # PLOT\n  # different output when there is a \"sample\" column\n  if(is.null(split_sample_by)){\n      plot = ggplot(dat, aes(x = var))+\n          geom_histogram(bins = 100, alpha = 0.5, fill = \"#56B4E9\")+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n\n\n  }else if(!is.null(split_sample_by)){\n\n    if(length(which(names(dat) == split_sample_by)) == 0){\n      message(paste0(\"You have indicated that you wanted to group plotted values by \", split_sample_by,\", but the data contains no such column.\")); break\n    }\n\n    # incorporate grouping variable\n    names(dat)[which(names(dat) == split_sample_by)] = \"split_sample_by\"\n    # make sure its a factor\n    dat$split_sample_by = as.factor(dat$split_sample_by)\n\n    colors = c(\"#56B4E9\",\"#009E73\", \"#E69F00\") # \"#79AC78\" #grDevices::colors()[grep('gr(a|e)y', grDevices::colors(), invert = T)]\n    colors = colors[1:length(unique(dat$split_sample_by))]\n\n      plot = ggplot(dat)+\n          geom_histogram(aes(x = var, fill = split_sample_by), bins = 100, alpha = 0.5)+\n          scale_fill_manual(values = colors, name = split_sample_by)+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n  }\n\n    # make second x-axis if we're working with standardised variables\n    if(length(grep(\"_stand\", var)) != 0){\n\n      # calculate mean from original variable\n      varOr = str_remove(var, \"_stand\")\n      mean = mean(dat[,varOr], na.rm=T)\n      sd = sd(dat[,varOr], na.rm=T)\n\n      # add secondary x axis\n      plot = plot+\n         scale_x_continuous(sec.axis = sec_axis(name = \"Raw values\", trans=~.*sd+mean))\n\n    }\n\n  plot = plot+theme(panel.border = element_blank())\n\n  return(plot)\n}\n\n# this onyl works for the correct naming of the variable names to diff, ratio and resid\ndescriptives = function(samples = c(\"HCP\", \"Share\", \"both\")){\n  # define statistics to include\n  stats = c(\"N\", \"TBV: Mean (SD)\", \"ICV: Mean (SD)\", \"cor(ICV,TBV)\",\n            \"*Difference score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\",\n            \"*Ratio score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\",\n            \"*Residual score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\")\n\n  # object to hold results\n  res = as.data.frame(matrix(ncol = length(samples)+1, nrow = length(stats)))\n  names(res) = c(\"Statistic\", samples)\n  res$Statistic = stats\n\n  for(i in samples){\n    # pull sample\n    dat = as.data.frame(get(i))\n\n    # N\n    N = sum(!is.na(dat$diff))\n    res[which(res$Statistic == \"N\"), which(names(res) == i)] = N\n\n    # TBV: Mean (SD)\n    mean = round(mean(dat$TBV, na.rm = T), digits = 2)\n    SD = signif(sd(dat$TBV, na.rm = T), digits = 2)\n    res[which(res$Statistic == \"TBV: Mean (SD)\"), which(names(res) == i)] = paste0(mean, \" (\", SD,\")\")\n\n    # ICV: Mean (SD)\n    mean = round(mean(dat$ICV, na.rm = T), digits = 2)\n    SD = signif(sd(dat$ICV, na.rm = T), digits = 2)\n    res[which(res$Statistic == \"ICV: Mean (SD)\"), which(names(res) == i)] = paste0(mean, \" (\", SD,\")\")\n\n    # ICV TBV correlation\n    cor = round(cor.test(dat$ICV, dat$TBV)$estimate, digits = 2)\n    res[which(res$Statistic == \"cor(ICV,TBV)\"), which(names(res) == i)] = cor\n\n    # Cycle through different scores\n    for(j in c(\"Difference\", \"Ratio\", \"Resid\")){\n        # determine variable that matches the right score\n        if(j == \"Difference\"){\n          VarName = \"diff\"\n        }else if(j == \"Ratio\"){\n          VarName = \"ratio\"\n        }else if(j == \"Resid\"){\n          VarName = \"resid\"\n        }\n\n        dat$var = dat[,VarName]\n\n        ### Calculate mean and SD\n        mean = round(mean(dat$var, na.rm=T), digits = 2)\n        sd = round(sd(dat$var, na.rm=T), digits = 2)\n        # find correct position in res to store result\n        index = grep(j, res$Statistic)\n        Cand = grep(\"Mean\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        # store mean result\n        res[pos, which(names(res) == i)] = paste0(mean, \" (\", sd, \")\")\n\n        ### Calculate median\n        median = round(median(dat$var, na.rm=T), digits = 2)\n        #store median result\n        Cand = grep(\"Median\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = median\n\n        ### Calculate range\n        min = round(min(dat$var, na.rm = T), digits = 2)\n        max = round(max(dat$var, na.rm = T), digits = 2)\n        # store results\n        Cand = grep(\"Range\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = paste0(min, \" to \", max)\n\n        ## Calculate variance\n        variance = signif(var(dat$var, na.rm = T), digit = 2)\n        # store variance result\n        Cand = grep(\"Variance\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = variance\n\n        ### calculate cut-off\n        if(j == \"Difference\"){\n          cutOff = mean(dat$var, na.rm = T)+(2*sd(dat$var, na.rm = T))\n        }else{\n            cutOff = mean(dat$var, na.rm = T)-(2*sd(dat$var, na.rm = T))\n        }\n        # store results\n        Cand = grep(\"Cut\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = round(cutOff, digit = 1)\n    }\n  }\n\n  return(res)\n}\n\n\n# define function to make ggplots prettier\nmake_pretty <- function(){\n  theme(text = element_text(size=6),\n        axis.text.x = element_text(size=4, colour='#696969'),\n        axis.text.y = element_blank(),\n        plot.title = element_text(face=\"bold\", colour='#1A1A1A', size=6, hjust = 0.5),\n        axis.title.x = element_text(face=\"bold\", colour='#1A1A1A', size=6),\n        axis.title.y = element_text(face=\"bold\", colour='#1A1A1A', size=6),\n        axis.line.x = element_blank(),\n        axis.line.y = element_blank(),\n        axis.ticks.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        panel.border = element_blank(),\n        axis.title.x.top = element_text(color = \"grey\", size=6, hjust=0))\n}\n```\n:::\n\n\n\n\n## Extract cross-sectionally processed neuroimaging data\n\nHere we aggregate neuroimaging measures to calculate lifetime atrophy scores (ICV, TBV), in addition to CSF, and T1-scaling factor (N = 46836). This was the phenotypic input data for the GWAS.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##############################\n# aim is to extract neuroimaging data for UKB from the IDP variables : ICV & TBV\n# also add T1 volumetric scaling factor (field ID 25000) & CSF (field ID: 26527)\n# downloaded N = 46836\nfile = fread(paste0(wd, list.files(path = wd, pattern = \"RAP_download_08022024_neuro\")))\nnames(file) = paste0(\"f.\", names(file))\nnames(file) = gsub(\"-\", \"_\", names(file), fixed = T)\n\n# keep ID, 26515 & 26521\nCols = grepl(\"f.eid|f.26515_2.0|26521_2.0|f.25000_2|26527_2\", names(file))\n\n# select columns of interest\nfile = file[, ..Cols]\n\n# name variables TBV and icv\nnames(file)[grep(\"f.26515\", names(file))] = \"TBV\"\nnames(file)[grep(\"f.26521\", names(file))] = \"ICV\"\nnames(file)[grep(\"f.25000\", names(file))] = \"T1ScalingFactor\"\nnames(file)[grep(\"f.26527\", names(file))] = \"CSF\"\n\n#######################\n# Quality control: \n# something must have gone wrong if TBV is larger than ICV - delete\ndelete = sum(file$ICV - file$TBV < 0, na.rm=T)\nprint(paste(delete, \" people have larger TBV than ICV, and will therefore be removed from the sample.\"))\nfile = file[file$ICV - file$TBV >= 0,]\n\n# also a participant has ICV > 5000 which would be 5 times thesize of the smaller brains in the sample - delete \nprint(paste(sum(file$ICV > 5000000), \" people have ICV > 5000000 which is 5 time larger than the average brain in the sample, and will therefore be removed from the sample.\"))\nfile = file[file$ICV <= 5000000,]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\nfile$ICV = file$ICV/1000\nfile$TBV = file$TBV/1000\n\n# estimate brain atrophy from single MRI scan\nfile$diff = file$ICV - file$TBV\nfile$ratio = file$TBV / file$ICV\n\nmodel <- lm(TBV ~ ICV, data = file)\nfile$resid = resid(model)\n\nfileNoMiss = file[!is.na(file$T1ScalingFactor),]\n\nmodel <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)\nfileNoMiss$residScalingFactor = resid(model)\n\n# merge back in with file\nfile = merge(file, fileNoMiss[,c(\"f.eid\", \"residScalingFactor\")], by = \"f.eid\", all.x=T)\n\n\n# standardise variables within one time-point\nfile$resid_stand = as.vector(scale(file$resid))\nfile$diff_stand = as.vector(scale(file$diff))\nfile$ratio_stand = as.vector(scale(file$ratio))\nfile$TBVstand = as.vector(scale(file$TBV))\nfile$ICVstand = as.vector(scale(file$ICV))\nfile$residScalingFactor_stand = as.vector(scale(file$residScalingFactor))\nfile$CSFstand = as.vector(scale(file$CSF))\n\n# for regenie to recognise, need to name ID column IID and add FID\nnames(file)[grep(\"f.eid\", names(file))] = \"IID\"\nfile$FID = file$IID\n\n# change order of the columns\norderedNames = c(\"FID\", \"IID\", names(file)[2:(length(names(file)) -1)])\nfile = file[, ..orderedNames]\n\n# write file\nfwrite(file, paste0(wd, \"/UKB_CrossNeuroIDP.txt\"), quote = F, col.names = T, sep = \"\\t\", na = \"NA\")\n```\n:::\n\n\nUpon inspection, I noticed that there are two pretty severe outliers: outside of 10 SDs. Remove those here because they had some impossible CSF values which were larger than ICV.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# read in data with all participants\ndat = fread(paste0(wd, \"/UKB_CrossNeuroIDP.txt\"))\n\n# delete all participants that have difference score larger than 10 SDs\ndat = dat[which(dat$diff_stand < 10),]\n# 2487172 2595043 are both not available for raw data so I can't look at whether anything has gone wrong with processing\n\n# there are also two participants with CSFstand > 10 which skew the distribution\ndat = dat[which(dat$CSFstand < 10),]\n\n# re-calculate reisudal measures after those deletions\n## first delete all residu measures\ndat$resid = NULL\ndat$residScalingFactor = NULL\n\n## second recaculate all resid measures\nmodel <- lm(TBV ~ ICV, data = dat)\ndat$resid = resid(model)\n\nfileNoMiss = dat[!is.na(dat$T1ScalingFactor),]\n\nmodel <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)\nfileNoMiss$residScalingFactor = resid(model)\n\n# merge back in with file\ndat = merge(dat, fileNoMiss[,c(\"FID\", \"residScalingFactor\")], by = \"FID\", all.x=T)\n\n# standardise variables within one time-point\ndat$resid_stand = as.vector(scale(dat$resid))\ndat$diff_stand = as.vector(scale(dat$diff))\ndat$ratio_stand = as.vector(scale(dat$ratio))\ndat$TBVstand = as.vector(scale(dat$TBV))\ndat$ICVstand = as.vector(scale(dat$ICV))\ndat$residScalingFactor_stand = as.vector(scale(dat$residScalingFactor))\ndat$CSFstand = as.vector(scale(dat$CSF))\n\nfwrite(dat, \"UKB_CrossNeuroIDP_noOutliers.txt\", quote = F, col.names = T, sep = \"\\t\", na = \"NA\")\n```\n:::\n\n\n\n\n## Extract covariates\n\nThese are the GWAS covariates.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sex: 31 (676893)\n# acquisition site: 54 (676893)\n# scanning day: 53 (676893) Day2day: investigating daily variability of MRI measures over half a year, Filevich et al., 2017; but actually studies suggest its mainly the time of day that matters (Identifying predictors of within-person variance in MRI-based brain volume estimates, Karch et al., 2019)\n# scanning month: 53\n### scan positions: 25756, 25757, 25758 (670476)\n\n#### extract scanning positions\nfile2 = fread(paste0(wd, list.files(path = wd, pattern = \"RAP_download_08022024_neuro\")))\nnames(file2) = paste0(\"f.\", names(file2))\nnames(file2) = gsub(\"-\", \"_\", names(file2), fixed = T)\n\n# keep ID,  & columns of interest\nCols = grepl(\"f.eid|f.25756_2|f.25757_2|f.25758_2\", names(file2))\n\n# select columns of interest\nfile2 = file2[, ..Cols]\n\n# change column names\nnames(file2)[grep(\"f.25756_2\", names(file2))] = \"xCoord\"\nnames(file2)[grep(\"f.25757_2\", names(file2))] = \"yCoord\"\nnames(file2)[grep(\"f.25758_2\", names(file2))] = \"zCoord\"\n\n#### extract sex, site, month, age\nfile = fread(paste0(wd, list.files(path = wd, pattern = \"RAP_download_08022024_covariates\")))\nnames(file) = paste0(\"f.\", names(file))\nnames(file) = gsub(\"-\", \"_\", names(file), fixed = T)\n\n# name variables TBV and icv\nnames(file)[grep(\"f.31\", names(file))] = \"sex\"\nnames(file)[grep(\"f.54\", names(file))] = \"site\"\n#names(file)[grep(\"f.53\", names(file))] = \"day\"\n#names(file)[grep(\"f.21022\", names(file))] = \"age_at_recruitment\"\nnames(file)[grep(\"f.52\", names(file))] = \"birth_month\"\nnames(file)[grep(\"f.53\", names(file))] = \"date_of_assessment\"\nnames(file)[grep(\"f.34\", names(file))] = \"birth_year\"\n\n# make sure site is categorical and represented in numbers\nfile$site[grep(\"Cheadle\", file$site)] = \"1\"\nfile$site[grep(\"Bristol\", file$site)] = \"2\"\nfile$site[grep(\"Newcastle\", file$site)] = \"3\"\nfile$site[grep(\"Reading\", file$site)] = \"4\"\nfile$site = as.factor(file$site)\n\n# work out assessment month\nfile$assessmentMonth = as.numeric(format(as.POSIXct(file$date_of_assessment), \"%m\"))\n\n# transform birth_month into numerics\nfile$birth_month[which(file$birth_month == \"January\")] = 1\nfile$birth_month[which(file$birth_month == \"February\")] = 2\nfile$birth_month[which(file$birth_month == \"March\")] = 3\nfile$birth_month[which(file$birth_month == \"April\")] = 4\nfile$birth_month[which(file$birth_month == \"May\")] = 5\nfile$birth_month[which(file$birth_month == \"June\")] = 6\nfile$birth_month[which(file$birth_month == \"July\")] = 7\nfile$birth_month[which(file$birth_month == \"August\")] = 8\nfile$birth_month[which(file$birth_month == \"September\")] = 9\nfile$birth_month[which(file$birth_month == \"October\")] = 10\nfile$birth_month[which(file$birth_month == \"November\")] = 11\nfile$birth_month[which(file$birth_month == \"December\")] = 12\n\nfile$birthday = 1\n\nfile$birth_date = as.Date(ISOdate(year = file$birth_year,\n                    month = file$birth_month, \n                    day = file$birthday))\n\n##### Work out age as the difference between date attended assessment center and birthday (we have month and year)\nfile$date_of_assessment = as.Date(file$date_of_assessment)\nfile$age = as.numeric(difftime(file$date_of_assessment, file$birth_date, units = \"days\"))/(365.5/12)\n\n# merge the two data files\nfile = merge(file, file2, by = \"f.eid\")\n\n# select columns of interest\nfile = file[,c(\"f.eid\", \"age\", \"sex\", \"assessmentMonth\", \"site\",\"xCoord\", \"yCoord\", \"zCoord\")]\n\n# make sex & assessment month a factor\nfile$assessmentMonth = as.factor(file$assessmentMonth)\nfile$sex[grep(\"Female\", file$sex)] = \"1\"\nfile$sex[grep(\"Male\", file$sex)] = \"0\"\nfile$sex = as.factor(file$sex)\n\n# genetic covariates saved in charleys file\ngenCovar = fread(\"/Cluster_Filespace/charley_ccace/Charley_UKB_OCT2020/Sample_QC_with_IDs_REM_19July2017.csv\")\nnames(genCovar)[which(names(genCovar) == \"ukb_id\")] = \"f.eid\"\n\n# store column names of columns of interest\ncovarNames = c(\"f.eid\", \"genotyping.array\", \"Batch\", paste0(\"PC\", 1:40))\ngenCovar = genCovar[, ..covarNames]\n\n# format factor variables\nnames(genCovar)[which(names(genCovar) == \"genotyping.array\")] = \"array\"\ngenCovar$array[grep(\"UKBB\", genCovar$array)] = \"0\"\ngenCovar$array[grep(\"UKBL\", genCovar$array)] = \"1\"\ngenCovar$array = as.factor(genCovar$array)\n\nnames(genCovar)[which(names(genCovar) == \"Batch\")] = \"batch\"\ngenCovar$batch = as.factor(genCovar$batch)\n\n# merge in with file\nfile = merge(file, genCovar, by = \"f.eid\")\n\n# for regenie to recognise, need to name ID column IID and add FID\nnames(file)[grep(\"f.eid\", names(file))] = \"IID\"\nfile$FID = file$IID\n\n# change order of the columns\norderedNames = c(\"FID\", \"IID\", names(file)[2:(length(names(file)) -1)])\nfile = file[, ..orderedNames]\n\n# write file\nfwrite(file, paste0(wd, \"/UKB_covarGWAS.txt\"), quote = F, col.names = T, sep = \"\\t\", na = \"NA\")\n# 45616 rows\n```\n:::\n\n\n\n## Correlations between phenotypes of interest and covariates\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##### this next section of code has been taken from REGENIE_step1_reAnalyse_resid.sh\n# read in pheno file\nall = fread(\"/CCACE_Shared/Anna_F/BrainAtrophy/data/UKB_CrossNeuroIDP_noOutliers.txt\")\n# read in fam file that restricts participants\nfam = fread(\"/CCACE_Shared/Anna_F/BrainAtrophy/data/geneticQC/ukb_neuroimaging_brainAtrophy_GWASinput.fam\")\n\n# keep only fam particiants\nall = all[all$FID %in% fam$V1,]\n\n# read in covar file to keep all non-missing participants\ncovar = fread(\"/CCACE_Shared/Anna_F/BrainAtrophy/data/UKB_covarGWAS.txt\")\ncovar = covar[complete.cases(covar),]\n\n# only keep complte covar cases\nall = merge(all, covar, by = c(\"IID\", \"FID\"))\n\n# recalculate resid score\nmodel <- lm(TBV ~ ICV, data = all)\nall$resid <- as.vector(resid(model))\n\n# standardised (this is the final phenotype modelled in GWAS)\nall$resid_stand = scale(all$resid)\n##################################\n\n# standardise some more covariates\nall$xCoord_stand <- scale(all$xCoord)\nall$yCoord_stand <- scale(all$yCoord)\nall$zCoord_stand <- scale(all$zCoord)\nall$age_stand <- scale(all$age)\n\n\n# get all possible combinations between variable names we want to consider (exclude genetic PCs to keep an overview - PCs will be fine)\nNames <- names(all)[!grepl(\"PC\", names(all))]\n# also exclude ID variables\nNames <- Names[!grepl(\"ID\", Names)] \n#only keep stand variables\nNames <- Names[grepl(\"stand\", Names)]\n\n# get all combinations of traits\ntraits <- expand.grid(Names, Names)\n# transofmr factor into character vectors\ntraits <- data.frame(lapply(traits, as.character), stringAsFactors = F)\n# delete combinations where trait is paired with itself\ntraits <- traits[traits$Var1 != traits$Var2,]\n\n# build data frame to hold output values for the correlations between traits\nresNames <- c(\"predictor\", \"outcome\", \"assoc\", \"se\", \"p\") \nres <- data.frame(matrix(nrow = nrow(traits), ncol = length(resNames)))\nnames(res) <- resNames\n\nres[,c(\"predictor\", \"outcome\")] <- traits[,c(\"Var1\", \"Var2\")]\n\n# cycle through the three phenos of interest\nfor(i in 1:nrow(res)){\n\n\t# extract the var names\n\tvars <- res[i, c(\"predictor\", \"outcome\")]\n\n\t# build model (the way expand.grid arranged the traits meant that all the continious traits of interest are in the second column - so here they are placed as the outcome variable in the model)\n\tmod <- lm(as.formula(paste0( as.character(vars[2]), \" ~ \", as.character(vars[1]))), data = all)\n\n\t# get summary of model\n\tmodR <- summary(mod)\n\t\n\t# extract and store results\n\tres[i, \"assoc\"] <- modR$coefficients[2,1]\n\tres[i, \"se\"] <- modR$coefficients[2,2]\n\tres[i, \"p\"] <- modR$coefficients[2,4]\n}\n\nfwrite(res, \"UKB_covar_assocs.table\", quote = F, col.names = T, sep = \"\\t\", na = \"NA\")\n```\n:::\n\n\n\n## Extract longitudinal estimates from this cross-sectional data\n\nWe had planned to longitudinally process UKB data from the initial and second neuroimaging visit. This however was not possible due to missing files for all but ~600 participants from field ID 20263 (missing files were mri/orig/001.mgz that need to be present in the FS output directory to run the longitudinal processing pipeline). We noticed this during the time that UKB stopped data downloads. Hence, we were not given permission to download raw MRI files (field 20253), meaning that, unfortunately, we had to work with tabulated data only, even to extract longitudinal estimates of brain change. For this reason, the output file created here is called: 'UKB_neuroNoLongProcess.txt'.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# it's aim is to extract neuroimaging data for UKB from the IDP variables \nfileID = list.files(pat=path,pattern=\"csv\")\n# read in file\nfile = fread(paste0(path, \"/\", fileID))\n# file doesnt like column names that start with number and it doesnt like -\nnames(file) = paste0(\"f.\",names(file))\nnames(file) = gsub(\"-\", \"_\", names(file), fixed = T)\n\n# keep ID, 26515 & 26521\nCols = grepl(\"f.eid|f.26515|26521\", names(file))\n\n# select columns of interest\nfile = file[, ..Cols]\n\n# melt data to get wave column\nfile = melt(file, id.vars = \"f.eid\", measure.vars = list(c(\"f.26515_2.0\", \"f.26515_3.0\"), c(\"f.26521_2.0\", \"f.26521_3.0\")), value.name = c(\"f.26515\", \"f.26521\"))\n\n# re-name varibale to wave\nnames(file)[which(names(file) == \"variable\")] = \"wave\"\n\n# add +1 for correct wave\nfile$wave = as.numeric(file$wave) + 1\n\n# name variables TBV and icv\nnames(file)[grep(\"f.26515\", names(file))] = \"TBV\"\nnames(file)[grep(\"f.26521\", names(file))] = \"ICV\"\n\n##############################\n# also add T1 volumetric scaling factor (field ID 25000) & CSF (field ID: 26527)\nfileID = list.files(pat=path,pattern=\"csv\")\n# read in file\nmore = fread(paste0(path, \"/\", fileID))\n# R doesnt like column names that start with number and it doesnt like -\nnames(more) = paste0(\"f.\",names(more))\nnames(more) = gsub(\"-\", \"_\", names(more), fixed = T)\n\n# keep ID, 26515 & 26521\nCols = grepl(\"f.eid|f.25000|26527\", names(more))\n\n# select columns of interest\nmore = more[, ..Cols]\n\n# melt data to get wave column\nmore = melt(more, id.vars = \"f.eid\", measure.vars = list(c(\"f.25000_2.0\", \"f.25000_3.0\"), c(\"f.26527_2.0\", \"f.26527_3.0\")), value.name = c(\"f.25000\", \"f.26527\"))\n\n# re-name varibale to wave\nnames(more)[which(names(more) == \"variable\")] = \"wave\"\n\n# add +1 for correct wave\nmore$wave = as.numeric(more$wave) + 1\n\n# name variables TBV and icv\nnames(more)[grep(\"f.25000\", names(more))] = \"T1ScalingFactor\"\nnames(more)[grep(\"f.26527\", names(more))] = \"CSF\"\n\n# merge with other data\nfile = merge(file, more, by = c(\"f.eid\", \"wave\"),all = T)\n##############################\n\n# Quality control: \n# something must have gone wrong if TBV is larger than ICV - delete\ndelete = sum(file$ICV - file$TBV < 0, na.rm=T)\nprint(paste(delete, \" people have larger TBV than ICV, and will therefore be removed from the sample.\")) #17 participants\nfile = file[file$ICV - file$TBV >= 0,]\n\n# also a participant has ICV > 5000 which would be 5 times thesize of the smaller brains in the sample - delete \nfile = file[file$ICV <= 5000000,]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\nfile$ICV = file$ICV/1000\nfile$TBV = file$TBV/1000\n\n# estimate brain atrophy from single MRI scan\nfile$diff = file$ICV - file$TBV\nfile$ratio = file$TBV / file$ICV\n\n##### derive the residuals for each time point separately \n## first wave (named wave 2 in UKB)\nfile1 = file[which(file$wave == 2),]\n\nmodel <- lm(TBV ~ ICV, data = file1)\nfile1$resid = resid(model)\n\n# also derive residual model for scaling factor\n# for some reason here we have an issue with missing data, so delete and re-merge\nfileNoMiss = file1[!is.na(file1$T1ScalingFactor),]\n\nmodel <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)\nfileNoMiss$residScalingFactor = resid(model)\n\n# merge back in with file\nfile1 = merge(file1, fileNoMiss[,c(\"f.eid\", \"residScalingFactor\")], by = \"f.eid\", all.x=T)\n\nsum(!is.na(fileNoMiss$residScalingFactor))\nsum(!is.na(file1$residScalingFactor))\n\n# standardise variables within one time-point\nfile1$resid_stand = as.vector(scale(file1$resid))\nfile1$diff_stand = as.vector(scale(file1$diff))\nfile1$ratio_stand = as.vector(scale(file1$ratio))\nfile1$TBVstand = as.vector(scale(file1$TBV))\nfile1$ICVstand = as.vector(scale(file1$ICV))\nfile1$residScalingFactor_stand = as.vector(scale(file1$residScalingFactor))\nfile1$CSFstand = as.vector(scale(file1$CSF))\n\n# wave 4\nfile3 = file[which(file$wave == 3),]\nmodel <- lm(TBV ~ ICV, data = file3)\nfile3$resid = resid(model)\n\n# also derive residual model for scaling factor\n# for some reason here we have an issue with missing data, so delete and re-merge\nfileNoMiss = file3[!is.na(file3$T1ScalingFactor),]\n\nmodel <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)\nfileNoMiss$residScalingFactor = resid(model)\n\n# merge back in with file\nfile3 = merge(file3, fileNoMiss[,c(\"f.eid\", \"residScalingFactor\")], by = \"f.eid\", all.x=T)\n\nsum(!is.na(fileNoMiss$residScalingFactor))\nsum(!is.na(file3$residScalingFactor))\n\n\n# standardise variables within one time-point\nfile3$resid_stand = as.vector(scale(file3$resid))\nfile3$diff_stand = as.vector(scale(file3$diff))\nfile3$ratio_stand = as.vector(scale(file3$ratio))\nfile3$TBVstand = as.vector(scale(file3$TBV))\nfile3$ICVstand = as.vector(scale(file3$ICV))\nfile3$residScalingFactor_stand = as.vector(scale(file3$residScalingFactor))\nfile3$CSFstand = as.vector(scale(file3$CSF))\n\n#merge the two waves back together\nfile = rbind(file1, file3)\n\n# only keep participants that have both measurement points\nfile = file[file$f.eid %in% file$f.eid[duplicated(file$f.eid)],]\n\n# store as txt file\nfwrite(file[,c(\"f.eid\", \"wave\", \"ICV\", \"TBV\", \"CSF\",  \"T1ScalingFactor\",\"diff\", \"ratio\", \"resid\", \"ICVstand\", \"TBVstand\", \"CSFstand\", \"resid_stand\", \"diff_stand\", \"ratio_stand\", \"residScalingFactor_stand\")], paste0(wd, \"/UKB_crossNeuroWave2_3.txt\"), quote = F, col.names = T, sep = \"\\t\")\n\n# make wide format \ntemp = reshape(file[, c(\"f.eid\", \"wave\", \"TBV\")], idvar = \"f.eid\", timevar = \"wave\", direction = \"wide\")\n\n#### Difference score \n# Step 2: calculate difference in TBV between wave 2 and wave 5\ntemp$TBVdiff_2to3 = temp$TBV.2 - temp$TBV.3\n\n###### Ratio score\n# Step 2: calculate difference in TBV between wave 2 and wave 5\ntemp$TBVratio_3to2 = temp$TBV.3 / temp$TBV.2\n\n###### Resid score\n# remove missing because results with missing produces weird dimensions\n#temp = temp[!is.na(temp$TBV.2),]\n#temp = temp[!is.na(temp$TBV.3),] \n# Step 2: calculate difference in TBV between wave 2 and wave 5\nmodel = lm(TBV.3 ~ TBV.2, data = temp)\ntemp$TBVresid_2to3 = resid(model)\n\n# standardise variables\ntemp$TBV.2_stand = scale(temp$TBV.2)\ntemp$TBV.3_stand = scale(temp$TBV.3)\ntemp$TBVdiff_2to3_stand = scale(temp$TBVdiff_2to3)\ntemp$TBVratio_3to2_stand = scale(temp$TBVratio_3to2)\ntemp$TBVresid_2to3_stand = scale(temp$TBVresid_2to3)\n\n# no need to keep TBV.2 and TBV.3\ntemp = temp[, c(-2,-3)]\n\n# merge back in with neuro\ntemp = merge(neuro, temp, by = \"f.eid\")\n\n# store as txt file\nfwrite(temp, paste0(wd, \"/UKB_neuroNoLongProcess.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n:::\n\n\n\n### UKB (initial scan)\n\n\nShown in Supplementary Figure 3: Distributions of TBV, ICV, and lifetime brain atrophy estimated with the residual, ratio, and difference method. Histograms are coloured by age groups. \n\n\n\n::: {.cell fig.dim='[20,8]'}\n\n```{.r .cell-code}\n####################################################\nUKB = fread(paste0(out, \"/UKB_CrossNeuroIDP_noOutliers.txt\"))\nage = fread(paste0(out, \"/UKB_covarGWAS.txt\"))\nUKB = merge(UKB, age[,c(\"FID\", \"age\")], by = \"FID\")\nUKB$Sample = \"UKB\"\nnames(UKB)[which(names(UKB) == \"IID\")] = \"ID\"\nnames(UKB)[which(names(UKB) == \"age\")] = \"Age\"\n\nUKB$Age <- UKB$Age / 12\n\n####################################################\n# make age groups\nUKB$Age_group <- NA\nUKB$Age_group[UKB$Age < 55] <- \"55 years and under\"\nUKB$Age_group[UKB$Age >= 55 & UKB$Age < 60] <- \"55 - 59\"\nUKB$Age_group[UKB$Age >= 60 & UKB$Age < 65] <- \"60 - 64\"\nUKB$Age_group[UKB$Age >= 65 & UKB$Age < 70] <- \"65 - 69\"\nUKB$Age_group[UKB$Age >= 70 & UKB$Age < 75] <- \"70 - 74\"\nUKB$Age_group[UKB$Age >= 75 & UKB$Age < 80] <- \"75 - 79\"\nUKB$Age_group[UKB$Age >= 80] <- \"80 years and over\"\n\np1=ggplot(UKB, aes(x=TBV, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"TBV\")+\n  theme_bw()\n\np2=ggplot(UKB, aes(x=ICV, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"ICV\")+\n  theme_bw()\n\np3=ggplot(UKB, aes(x=resid_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Residual score\")+\n  theme_bw()\n\np4=ggplot(UKB, aes(x=ratio_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Ratio score\")+\n  theme_bw()\n\np5=ggplot(UKB, aes(x=diff_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Difference score\")+\n  theme_bw()\n\npUKB <- ggarrange(p1,p2,p3,p4,p5, nrow = 1, common.legend = T, legend = \"bottom\")\n# add title\npUKB <- annotate_figure(pUKB, top = text_grob(\"UKB (inital neuroimaging visit)\",face = \"bold\", size = 14))\n\n#ggsave(paste0(out,\"phenotypic/UKB_disttributions.jpg\"), bg = \"white\",plot = pUKB, width = 30, height = 10, units = \"cm\", dpi = 300)\npUKB\n```\n\n::: {.cell-output-display}\n![](UKB_neuro_files/figure-html/unnamed-chunk-8-1.png){width=1920}\n:::\n:::\n\n\n### UKB (second scan)\n\n\nShown in Supplementary Figure 3: Distributions of TBV, ICV, and lifetime brain atrophy estimated with the residual, ratio, and difference method. Histograms are coloured by age groups. \n\n\n\n::: {.cell fig.dim='[20,8]'}\n\n```{.r .cell-code}\n####################################################\nUKB = fread(paste0(out, \"/UKB_neuroNoLongProcess.txt\"))\nnames(UKB)[grepl(\"f.eid\", names(UKB))] <- \"FID\"\n# restrict to second neuroimaging visit (i.e., third visit altogether)\nUKB3 = UKB[UKB$wave == 3,]\n# add age info\nage = fread(paste0(out, \"/UKB_covarGWAS.txt\"))\nUKB3 = merge(UKB3, age[,c(\"FID\", \"age\")], by = \"FID\")\nnames(UKB3)[which(names(UKB3) == \"age.x\")] = \"Age\"\n\nUKB3$Age <- UKB3$Age / 12\n\n####################################################\n# make age groups\nUKB3$Age_group <- NA\nUKB3$Age_group[UKB3$Age < 55] <- \"55 years and under\"\nUKB3$Age_group[UKB3$Age >= 55 & UKB3$Age < 60] <- \"55 - 59\"\nUKB3$Age_group[UKB3$Age >= 60 & UKB3$Age < 65] <- \"60 - 64\"\nUKB3$Age_group[UKB3$Age >= 65 & UKB3$Age < 70] <- \"65 - 69\"\nUKB3$Age_group[UKB3$Age >= 70 & UKB3$Age < 75] <- \"70 - 74\"\nUKB3$Age_group[UKB3$Age >= 75 & UKB3$Age < 80] <- \"75 - 79\"\nUKB3$Age_group[UKB3$Age >= 80] <- \"80 years and over\"\n\np1=ggplot(UKB3, aes(x=TBV, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"TBV\")+\n  theme_bw()\n\np2=ggplot(UKB3, aes(x=ICV, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"ICV\")+\n  theme_bw()\n\np3=ggplot(UKB3, aes(x=resid_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Residual score\")+\n  theme_bw()\n\np4=ggplot(UKB3, aes(x=ratio_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Ratio score\")+\n  theme_bw()\n\np5=ggplot(UKB3, aes(x=diff_stand, fill=Age_group)) +\n  geom_histogram()+\n  scale_fill_manual(\"Age groups\", values = c(\"#292f56\", \"#1e4572\", \"#005c8b\", \"#008ba0\", \"#00bca1\",\"#69e882\", \"#acfa70\"))+\n  xlab(\"Difference score\")+\n  theme_bw()\n\npUKB3 <- ggarrange(p1,p2,p3,p4,p5, nrow = 1, common.legend = T, legend = \"bottom\")\n# add title\npUKB3 <- annotate_figure(pUKB3, top = text_grob(\"UKB (second neuroimaging visit)\",face = \"bold\", size = 14))\n\n#ggsave(paste0(out,\"phenotypic/UKB3_disttributions.jpg\"), bg = \"white\",plot = pUKB3, width = 30, height = 10, units = \"cm\", dpi = 300)\npUKB3\n```\n\n::: {.cell-output-display}\n![](UKB_neuro_files/figure-html/unnamed-chunk-9-1.png){width=1920}\n:::\n:::\n\n\n\n### Display raw change in TBV\n\n\n::: {.cell fig.dim='[5,5]'}\n\n```{.r .cell-code}\n# read in UKB neuro data\nUKB = fread(paste0(out, \"/UKB_neuroNoLongProcess.txt\"))\n\nplot = ggplot()+\n  geom_point(data = UKB, aes(x = wave, y = TBV, group = f.eid),color = \"#82A0D8\", size = .5)+\n  geom_line(data = UKB, aes(x = wave, y = TBV, group = f.eid), color = \"#8DDFCB\", linewidth = 0.2, alpha = .2) +\n  scale_x_continuous(breaks = c(2,3))+\n  ylab(bquote('TBV in '~mm^3))+\n  xlab(\"Assessment visit\")+\n    theme(legend.position = \"none\")+\n    theme_bw()+\n    theme(text = element_text(size=15),\n          plot.margin=unit(c(1, 1, 1, 1), \"cm\"),\n          axis.text.y = element_text(size =15),\n          axis.text.x = element_text(size =15),\n          panel.border = element_blank())\n\n# get average measures\nmean2 = mean(UKB$TBV[which(UKB$wave == 2)],  na.rm=T)\nlabel2 = paste0(\"Mean = \", round(mean2, digits = 2))\n\nmean3 = mean(UKB$TBV[which(UKB$wave == 3)],  na.rm=T)\nlabel3 = paste0(\"Mean = \", round(mean3, digits = 2))\n\navg <- data.frame(x = c(2,3),\n                  y = c(mean2,mean3),\n                  label = c(label2, label3))\n\navg$yLabel = min(UKB$TBV, na.rm=T)\n\nplot=plot + geom_point(data = avg, aes(x=x,y=y), shape = 4, color = \"red\")+\n  geom_line(data = avg, aes(x=x,y=y), color = \"red\")+\n  #geom_text(data = avg, aes(x=x,y=yLabel, label = label), angle = 90, color = \"red\", vjust = 0, hjust = 0)\n  annotate(\"text\", x = 2.05, y = min(UKB$TBV, na.rm=T)-50, label = paste0(\"Mean = \", round(mean2, digits = 2)), hjust = 0, color = \"red\", angle = 90)+\n  annotate(\"text\", x = 2.95, y = min(UKB$TBV, na.rm=T)-50, label = paste0(\"Mean = \", round(mean3, digits = 2)), hjust = 0, color = \"red\", angle = 90)\n\n#ggsave(paste0(out,\"phenotypic/UKB_longChange.jpg\"), bg = \"white\",plot = plot, width = 10, height = 10, units = \"cm\", dpi = 200)\nplot\n```\n\n::: {.cell-output-display}\n![](UKB_neuro_files/figure-html/rawChange-1.png){width=480}\n:::\n:::\n\n\n### Final distributions for longitudinally-observed atrophic change measures\n\nFirst define `plot_hist` function.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_hist <- function(dat = dat, var = \"diff_stand\", split_sample_by = NULL){\n  # install packages if they don't already exits\n  packages = c(\"ggplot2\",\"stringr\", \"tidyr\", \"dplyr\")\n  install.packages(setdiff(packages, rownames(installed.packages())))\n  # load packages\n  library(ggplot2)\n  library(stringr)\n  library(tidyr)\n  library(dplyr)\n\n  # make sure input data is data.frame\n  dat = as.data.frame(dat)\n  # rename for simplicity\n  dat$var = dat[,var]\n\n  # calculate summary stats\n    df_stats <-\n        dat %>%\n        summarize(\n          mean = mean(var, na.rm=T),\n          median = median(var, na.rm=T)\n        ) %>%\n        gather(key = Statistic, value = value, mean:median)\n\n    # calculate SD cutoffs\n    insert = c(\"+2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) + 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    insert = c(\"-2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) - 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    # format\n    df_stats$value <- as.numeric(df_stats$value)\n\n    # consider one-sided nature of cut-off\n    # if difference score, we use the upper 2 SD limit\n    # if ratio or residual score, we use the lower 2 SD limit\n    if(var == \"diff\" | var == \"diff_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"-2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }else if(var == \"ratio\" | var == \"resid\" | var == \"ratio_stand\" | var == \"resid_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"+2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }\n\n\n  # PLOT\n  # different output when there is a \"sample\" column\n  if(is.null(split_sample_by)){\n      plot = ggplot(dat, aes(x = var))+\n          geom_histogram(bins = 100, alpha = 0.5, fill = \"#56B4E9\")+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n\n\n  }else if(!is.null(split_sample_by)){\n\n    if(length(which(names(dat) == split_sample_by)) == 0){\n      message(paste0(\"You have indicated that you wanted to group plotted values by \", split_sample_by,\", but the data contains no such column.\")); break\n    }\n\n    # incorporate grouping variable\n    names(dat)[which(names(dat) == split_sample_by)] = \"split_sample_by\"\n    # make sure its a factor\n    dat$split_sample_by = as.factor(dat$split_sample_by)\n\n    colors = c(\"#56B4E9\",\"#009E73\", \"#E69F00\") # \"#79AC78\" #grDevices::colors()[grep('gr(a|e)y', grDevices::colors(), invert = T)]\n    colors = colors[1:length(unique(dat$split_sample_by))]\n\n      plot = ggplot(dat)+\n          geom_histogram(aes(x = var, fill = split_sample_by), bins = 100, alpha = 0.5)+\n          scale_fill_manual(values = colors, name = split_sample_by)+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n  }\n\n    # make second x-axis if we're working with standardised variables\n    if(length(grep(\"_stand\", var)) != 0){\n\n      # calculate mean from original variable\n      varOr = str_remove(var, \"_stand\")\n      mean = mean(dat[,varOr], na.rm=T)\n      sd = sd(dat[,varOr], na.rm=T)\n\n      # add secondary x axis\n      plot = plot+\n         scale_x_continuous(sec.axis = sec_axis(name = \"Raw values\", trans=~.*sd+mean))\n\n    }\n\n  plot = plot+theme(panel.border = element_blank())\n\n  return(plot)\n}\n```\n:::\n\n\n\nNote that I  noticed the extreme outliers only later on in the analysis process, which is why this first step cleaning the measures is included (nature of an organic document I guess, sorry!).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUKB = fread(paste0(out, \"/UKB_neuroNoLongProcess.txt\"))\n# keep only one wave (long data is duplicated here)\nUKB2 = UKB[which(UKB$wave == 2), ]\n\nUKB2 <- UKB2[which(UKB2$TBVdiff_2to3_stand < 10),]\nUKB2 <- UKB2[which(UKB2$TBVdiff_2to3_stand > (-10)),]\n\nUKB2 <- UKB2[which(UKB2$TBVratio_3to2_stand < 10),]\nUKB2 <- UKB2[which(UKB2$TBVratio_3to2_stand > (-10)),]\n\nUKB2 <- UKB2[which(UKB2$TBVresid_2to3_stand < 10),]\nUKB2 <- UKB2[which(UKB2$TBVresid_2to3_stand > (-10)),]\n\n\n# difference score\np1 = plot_hist(dat = UKB2, var = \"TBVdiff_2to3_stand\")+\n  xlab(\"TBV1 - TBV2\\n(Difference score)\")+\n  geom_histogram(fill = \"#D81B60\")+\n  make_pretty()\np1$layers[[2]] = NULL\n# ratio score\np2 = plot_hist(dat = UKB2, var = \"TBVratio_3to2_stand\")+\n  xlab(\"TBV2 divided by TBV1\\n(Ratio score)\")+\n  geom_histogram(fill = \"#FFC107\")+\n  make_pretty()\np2$layers[[2]] = NULL\n# resid score\np3 = plot_hist(dat = UKB2, var = \"TBVresid_2to3_stand\")+\n  xlab(\"TBV2 ~ TBV1\\n(Residual score)\")+\n  geom_histogram(fill = \"#004D40\")+\n  make_pretty()\np3$layers[[2]] = NULL\n\nplot = plot_grid(p1, p2, p3, nrow=1, labels = c(\"A\",\"B\",\"C\"), label_size = 6, rel_widths = c(1,1,1))\n\n#ggsave(paste0(out, \"phenotypic/UKBlong_distribution.png\"), plot = plot, width = 11, height = 5, units = \"cm\", dpi = 600)\nplot\n```\n\n::: {.cell-output-display}\n![](UKB_neuro_files/figure-html/longHist-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "UKB_neuro_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}