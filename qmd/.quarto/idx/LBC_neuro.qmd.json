{"title":"LBC1936: Neuroimaging data preparation","markdown":{"yaml":{"title":"LBC1936: Neuroimaging data preparation","format":{"html":{"code-fold":true}},"author":"Anna Elisabeth Furtjes","date":"`r format(Sys.time(), '%d %B %Y')`","output":"html","doi":"test"},"headingText":"quarto::quarto_render(input = \"LBC_neuro.qmd\", output_file = \"LBC_neuro.html\")","containsRefs":false,"markdown":"\n\n------------------------------------------------------------------------\n\n```{r setup, include=F, warning=F, message=F, eval=T}\nload(\"paths.RData\")\nknitr::opts_knit$set(root.dir = wd)\n```\n\nCode displayed here was used to obtain neuroimaging measures: TBV, ICV, LBA (difference, ratio, residual scores).\nThese measures were obtained for all waves from cross-sectionally processed data, and from longitudinal data considering waves 2 and 5. \n\n\nThe LBC neuroimaging data was processed with FS v5.1, which does not produce `BrainSegNotVent` estimates that we pre-registered to use across all samples. Instead, we derive TBV as the sum of GMV (cortical and subcortical should also include cerebellum) + cerebellum WMV + cerebral WMV, as was done in a previous [paper](https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.25572). One participant was excluded because TBV estimate was larger than ICV estimate - total of 269 participants with two assessments.\n\n\n## Load packages\n\n```{r, eval =F}\nlibrary(cowplot)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(data.table)\nlibrary(stringr)\nlibrary(dplyr)\n```\n\n\n## Define functions\n\nFunctions `plot_hist` and descriptives expect input data set to contain variables called diff, ratio, resid. `plot_hist` can also handle diff_stand, ratio_stand, resid_stand and will add an extra x-axis if input are standardised variables.\n\n```{r, eval =F}\nplot_hist <- function(dat = dat, var = \"diff_stand\", split_sample_by = NULL){\n  # install packages if they don't already exits\n  packages = c(\"ggplot2\",\"stringr\", \"tidyr\", \"dplyr\")\n  install.packages(setdiff(packages, rownames(installed.packages())))\n  # load packages\n  library(ggplot2)\n  library(stringr)\n  library(tidyr)\n  library(dplyr)\n\n  # make sure input data is data.frame\n  dat = as.data.frame(dat)\n  # rename for simplicity\n  dat$var = dat[,var]\n\n  # calculate summary stats\n    df_stats <-\n        dat %>%\n        summarize(\n          mean = mean(var, na.rm=T),\n          median = median(var, na.rm=T)\n        ) %>%\n        gather(key = Statistic, value = value, mean:median)\n\n    # calculate SD cutoffs\n    insert = c(\"+2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) + 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    insert = c(\"-2 SDs\", as.numeric(df_stats[which(df_stats$Statistic == \"mean\"), \"value\"]) - 2*sd(dat$var, na.rm=T))\n    df_stats <- rbind(df_stats, insert)\n\n    # format\n    df_stats$value <- as.numeric(df_stats$value)\n\n\n\n    # consider one-sided nature of cut-off\n    # if difference score, we use the upper 2 SD limit\n    # if ratio or residual score, we use the lower 2 SD limit\n    if(var == \"diff\" | var == \"diff_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"-2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }else if(var == \"ratio\" | var == \"resid\" | var == \"ratio_stand\" | var == \"resid_stand\"){\n      df_stats$value[which(df_stats$Statistic == \"+2 SDs\")]<-NA\n      # changed my mind, no need for median\n      df_stats <- df_stats[-which(df_stats$Statistic == \"median\"),]\n      # changed my mind, no need for mean either, it's just distracting\n      df_stats <- df_stats[-which(df_stats$Statistic == \"mean\"),]\n    }\n\n\n  # PLOT\n  # different output when there is a \"sample\" column\n  if(is.null(split_sample_by)){\n      plot = ggplot(dat, aes(x = var))+\n          geom_histogram(bins = 100, alpha = 0.5, fill = \"#56B4E9\")+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n\n\n  }else if(!is.null(split_sample_by)){\n\n    if(length(which(names(dat) == split_sample_by)) == 0){\n      message(paste0(\"You have indicated that you wanted to group plotted values by \", split_sample_by,\", but the data contains no such column.\")); break\n    }\n\n    # incorporate grouping variable\n    names(dat)[which(names(dat) == split_sample_by)] = \"split_sample_by\"\n    # make sure its a factor\n    dat$split_sample_by = as.factor(dat$split_sample_by)\n\n    colors = c(\"#56B4E9\",\"#009E73\", \"#E69F00\") # \"#79AC78\" #grDevices::colors()[grep('gr(a|e)y', grDevices::colors(), invert = T)]\n    colors = colors[1:length(unique(dat$split_sample_by))]\n\n      plot = ggplot(dat)+\n          geom_histogram(aes(x = var, fill = split_sample_by), bins = 100, alpha = 0.5)+\n          scale_fill_manual(values = colors, name = split_sample_by)+\n          geom_vline(data = df_stats, aes(xintercept = value, color = Statistic), size = 0.5)+\n          xlab(var)+\n          ylab(\"Count\")+\n          theme_bw()\n  }\n\n\n    # make second x-axis if we're working with standardised variables\n    if(length(grep(\"_stand\", var)) != 0){\n\n      # calculate mean from original variable\n      varOr = str_remove(var, \"_stand\")\n      mean = mean(dat[,varOr], na.rm=T)\n      sd = sd(dat[,varOr], na.rm=T)\n\n      # add secondary x axis\n      plot = plot+\n         scale_x_continuous(sec.axis = sec_axis(name = \"Raw values\", trans=~.*sd+mean))\n\n    }\n\n  plot = plot+theme(panel.border = element_blank())\n\n  return(plot)\n}\n\n# this onyl works for the correct naming of the variable names to diff, ratio and resid\ndescriptives = function(samples = c(\"HCP\", \"Share\", \"both\")){\n  # define statistics to include\n  stats = c(\"N\", \"TBV: Mean (SD)\", \"ICV: Mean (SD)\", \"cor(ICV,TBV)\",\n            \"*Difference score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\",\n            \"*Ratio score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\",\n            \"*Residual score*\", \"Mean (SD)\", \"Median\", \"Range\", \"Variance\", \"Cut off\")\n\n  # object to hold results\n  res = as.data.frame(matrix(ncol = length(samples)+1, nrow = length(stats)))\n  names(res) = c(\"Statistic\", samples)\n  res$Statistic = stats\n\n  for(i in samples){\n    # pull sample\n    dat = as.data.frame(get(i))\n\n    # N\n    N = sum(!is.na(dat$diff))\n    res[which(res$Statistic == \"N\"), which(names(res) == i)] = N\n\n    # TBV: Mean (SD)\n    mean = round(mean(dat$TBV, na.rm = T), digits = 2)\n    SD = signif(sd(dat$TBV, na.rm = T), digits = 2)\n    res[which(res$Statistic == \"TBV: Mean (SD)\"), which(names(res) == i)] = paste0(mean, \" (\", SD,\")\")\n\n    # ICV: Mean (SD)\n    mean = round(mean(dat$ICV, na.rm = T), digits = 2)\n    SD = signif(sd(dat$ICV, na.rm = T), digits = 2)\n    res[which(res$Statistic == \"ICV: Mean (SD)\"), which(names(res) == i)] = paste0(mean, \" (\", SD,\")\")\n\n    # ICV TBV correlation\n    cor = round(cor.test(dat$ICV, dat$TBV)$estimate, digits = 2)\n    res[which(res$Statistic == \"cor(ICV,TBV)\"), which(names(res) == i)] = cor\n\n    # Cycle through different scores\n    for(j in c(\"Difference\", \"Ratio\", \"Resid\")){\n        # determine variable that matches the right score\n        if(j == \"Difference\"){\n          VarName = \"diff\"\n        }else if(j == \"Ratio\"){\n          VarName = \"ratio\"\n        }else if(j == \"Resid\"){\n          VarName = \"resid\"\n        }\n\n        dat$var = dat[,VarName]\n\n        ### Calculate mean and SD\n        mean = round(mean(dat$var, na.rm=T), digits = 2)\n        sd = round(sd(dat$var, na.rm=T), digits = 2)\n        # find correct position in res to store result\n        index = grep(j, res$Statistic)\n        Cand = grep(\"Mean\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        # store mean result\n        res[pos, which(names(res) == i)] = paste0(mean, \" (\", sd, \")\")\n\n        ### Calculate median\n        median = round(median(dat$var, na.rm=T), digits = 2)\n        #store median result\n        Cand = grep(\"Median\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = median\n\n        ### Calculate range\n        min = round(min(dat$var, na.rm = T), digits = 2)\n        max = round(max(dat$var, na.rm = T), digits = 2)\n        # store results\n        Cand = grep(\"Range\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = paste0(min, \" to \", max)\n\n        ## Calculate variance\n        variance = signif(var(dat$var, na.rm = T), digit = 2)\n        # store variance result\n        Cand = grep(\"Variance\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = variance\n\n        ### calculate cut-off\n        if(j == \"Difference\"){\n          cutOff = mean(dat$var, na.rm = T)+(2*sd(dat$var, na.rm = T))\n        }else{\n            cutOff = mean(dat$var, na.rm = T)-(2*sd(dat$var, na.rm = T))\n        }\n        # store results\n        Cand = grep(\"Cut\", res$Statistic)\n        pos = Cand[which(Cand > index)][1]\n        res[pos, which(names(res) == i)] = round(cutOff, digit = 1)\n    }\n  }\n\n  return(res)\n}\n```\n\n\n\n## Extract from cross-sectional FS processing stream output\n\n\n\nData from the cross-sectional processing stream is used in all cases where samples are compared, as well as in analyses where cross-sectional and longitudinal measures are directly compared.\n\nThe naming is kind of confusing and here I am using the naming as the folder are called. There are wave 1, wave 2, wave 3 and wave 4 (which technically are waves 2,3,4,5 and scans 1,2,3,4), but that's what they were called during processing.\n\n### Tabulate FS data\n\n```{bash FS, eval =F}\n#!/bin/bash\n# Extract FreeSurfer variables (volume, area, thickness) for our LBC1936 W2 (scan 1) cross-sectional subjects\n# Colin Buchanan, 2022\n# Colin's script was adapted to extract cross-sectional estimates from LBC at wave 5\n\n\n# first, create subjects list of participants with wave 5 data\n#R\n\n#setwd(\"/Brain_Imaging/LBC1936_FS_long/LBC_long_W4\")\n# note that all subjects in this directory without a wave are the templates and the ones with a wave but without 'long' should be the longitudinally processed waves\n# list dirs\n#dirs = dir()\n# keep only W4 because it's visit 5\n#dirs = dirs[grepl(\"W4\", dirs)]\n# remove long scans\n#dirs = dirs[!grepl(\".long.\", dirs)]\n\n#write.table(dirs, \"/CCACE_Shared/Anna_F/BrainAtrophy/scripts/LBClong/subjects_wave3.csv\", col.names=F, row.names=F, quote=F, sep=\"\\t\")\n## use this ID list to extract measurements from FS dirs\n\n\nFREESURFER_HOME=/Cluster_Filespace/mharris4/LBC_long_W4/freesurfer510\n$FREESURFER_HOME/SetUpFreeSurfer.sh\nout=\"/CCACE_Shared/Anna_F/BrainAtrophy/data\"\nref1=\"/CCACE_Shared/Anna_F/BrainAtrophy/scripts/LBClong/subjects_wave1.csv\"\nref2=\"/CCACE_Shared/Anna_F/BrainAtrophy/scripts/LBClong/subjects_wave2.csv\"\nref3=\"/CCACE_Shared/Anna_F/BrainAtrophy/scripts/LBClong/subjects_wave3.csv\"\nref4=\"/CCACE_Shared/Anna_F/BrainAtrophy/scripts/LBClong/subjects_wave4.csv\"\n\n\nSUBJECTS_DIR=/Brain_Imaging/LBC1936_FS_long/LBC_long_W4\n\n# Wave1 \nasegstats2table --subjectsfile $ref1 --meas volume --common-segs --delimiter comma --tablefile \"${out}/LBC1936_global_w1_cross.csv\"\n\n# Wave2 \nasegstats2table --subjectsfile $ref2 --meas volume --common-segs --delimiter comma --tablefile \"${out}/LBC1936_global_w2_cross.csv\"\n\n# Wave3\nasegstats2table --subjectsfile $ref3 --meas volume --common-segs --delimiter comma --tablefile \"${out}/LBC1936_global_w3_cross.csv\"\n\n# Wave4\nasegstats2table --subjectsfile $ref4 --meas volume --common-segs --delimiter comma --tablefile \"${out}/LBC1936_global_w4_cross.csv\"\n```\n\n\n### Format Wave 1\n\n```{r, eval =F}\n# read in cross-stats\n## wave 1\ncrossDir=\"/Brain_Imaging/LBC1936_FS_long/freesurfer_crosssect_stats\"\ncross = fread(paste0(crossDir, \"/global_w2.csv\"), data.table=F)\n# the naming here is super confusing because it switches from wave 1 to scan 1 ...\n# but the actual participant names definitively say which wave this scan is from and it's (wave 1 naming, which corresponds to the second wave but first scan - so confusing)\n# I will name it below to reflect the folder names (i.e., wave 1 in this case)\nnames(cross) = gsub(\"-\", \".\", names(cross), fixed = T)\n\n# format each of those variables to long format\n## TotalGrayVol\n## Right.Cerebellum.White.Matter\n## Left.Cerebellum.White.Matter\ncrossLBC = cross[ , c(1, grep(\"TotalGrayVol|Right.Cerebellum.White.Matter|Left.Cerebellum.White.Matter|CorticalWhiteMatterVol|CSF|IntraCranialVol\", names(cross))) ]\n# remove lh & rhCorticalWhiteMatterVol (because whole measure is also included)\ncrossLBC = crossLBC[, !grepl(\"rh|lh\", names(crossLBC))]\n\n# calculate sum of the regions\ncrossLBC$TBV = rowSums(crossLBC[,c(\"TotalGrayVol\", \"Right.Cerebellum.White.Matter\", \"Left.Cerebellum.White.Matter\", \"CorticalWhiteMatterVol\")], na.rm = F)\n\n# rename for easier names\nnames(crossLBC)[grep(\"Measure:volume\", names(crossLBC))] = \"lbc36no\"\nnames(crossLBC)[grep(\"IntraCranialVol\", names(crossLBC))] = \"ICV\"\n\ncrossLBC = crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\")]\n\n# two participants have a smaller ICV than TBV sum(crossLBC$ICV - crossLBC$TBV < 0)\n# must be an error (LBC360213 & LBC361303)\ncrossLBC = crossLBC[-which(crossLBC$ICV - crossLBC$TBV <0),]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\ncrossLBC$ICV = crossLBC$ICV/1000\ncrossLBC$TBV = crossLBC$TBV/1000\n\n# estimate brain atrophy from single MRI scan\ncrossLBC$diff = crossLBC$ICV - crossLBC$TBV\ncrossLBC$ratio = crossLBC$TBV / crossLBC$ICV\n\n##### derive the residuals for each time point separately \nmodel <- lm(TBV ~ ICV, data = crossLBC)\ncrossLBC$resid = resid(model)\n\n# standardise variables within one time-point\ncrossLBC$resid_stand = as.vector(scale(crossLBC$resid))\ncrossLBC$diff_stand = as.vector(scale(crossLBC$diff))\ncrossLBC$ratio_stand = as.vector(scale(crossLBC$ratio))\ncrossLBC$TBVstand = as.vector(scale(crossLBC$TBV))\ncrossLBC$ICVstand = as.vector(scale(crossLBC$ICV))\ncrossLBC$CSFstand = as.vector(scale(crossLBC$CSF))\n\n# rename participant labels to match global naming\ncrossLBC$lbc36no = stringr::str_remove(crossLBC$lbc36no, pattern = \"_W1\")\n\n# store as txt file\nfwrite(crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\", \"diff\", \"ratio\", \"resid\", \"ICVstand\", \"TBVstand\", \"CSFstand\", \"resid_stand\", \"diff_stand\", \"ratio_stand\")], paste0(wd, \"/LBC1936_crossNeuroWave1.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n### Format Wave 2\n\n```{r, eval =F}\n# read in cross-stats\n## wave 2\ncrossDir=\"/CCACE_Shared/Anna_F/BrainAtrophy/data\"\ncross = fread(paste0(crossDir, \"/LBC1936_global_w2_cross.csv\"), data.table=F)\nnames(cross) = gsub(\"-\", \".\", names(cross), fixed = T)\n\n# format each of those variables to long format\n## TotalGrayVol\n## Right.Cerebellum.White.Matter\n## Left.Cerebellum.White.Matter\ncrossLBC = cross[ , c(1, grep(\"TotalGrayVol|Right.Cerebellum.White.Matter|Left.Cerebellum.White.Matter|CorticalWhiteMatterVol|CSF|IntraCranialVol\", names(cross))) ]\n# remove lh & rhCorticalWhiteMatterVol (because whole measure is also included)\ncrossLBC = crossLBC[, !grepl(\"rh|lh\", names(crossLBC))]\n\n# calculate sum of the regions\ncrossLBC$TBV = rowSums(crossLBC[,c(\"TotalGrayVol\", \"Right.Cerebellum.White.Matter\", \"Left.Cerebellum.White.Matter\", \"CorticalWhiteMatterVol\")], na.rm = F)\n\n# rename for easier names\nnames(crossLBC)[grep(\"Measure:volume\", names(crossLBC))] = \"lbc36no\"\nnames(crossLBC)[grep(\"IntraCranialVol\", names(crossLBC))] = \"ICV\"\n\ncrossLBC = crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\")]\n\n# two participants have a smaller ICV than TBV sum(crossLBC$ICV - crossLBC$TBV < 0)\n# must be an error (LBC360213 & LBC361303)\ncrossLBC = crossLBC[-which(crossLBC$ICV - crossLBC$TBV <0),]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\ncrossLBC$ICV = crossLBC$ICV/1000\ncrossLBC$TBV = crossLBC$TBV/1000\n\n# estimate brain atrophy from single MRI scan\ncrossLBC$diff = crossLBC$ICV - crossLBC$TBV\ncrossLBC$ratio = crossLBC$TBV / crossLBC$ICV\n\n##### derive the residuals for each time point separately \nmodel <- lm(TBV ~ ICV, data = crossLBC)\ncrossLBC$resid = resid(model)\n\n# standardise variables within one time-point\ncrossLBC$resid_stand = as.vector(scale(crossLBC$resid))\ncrossLBC$diff_stand = as.vector(scale(crossLBC$diff))\ncrossLBC$ratio_stand = as.vector(scale(crossLBC$ratio))\ncrossLBC$TBVstand = as.vector(scale(crossLBC$TBV))\ncrossLBC$ICVstand = as.vector(scale(crossLBC$ICV))\ncrossLBC$CSFstand = as.vector(scale(crossLBC$CSF))\n\n# rename participant labels to match global naming\ncrossLBC$lbc36no = stringr::str_remove(crossLBC$lbc36no, pattern = \"_W2\")\n\n# store as txt file\nfwrite(crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\", \"diff\", \"ratio\", \"resid\", \"ICVstand\", \"TBVstand\", \"CSFstand\", \"resid_stand\", \"diff_stand\", \"ratio_stand\")], paste0(wd, \"/LBC1936_crossNeuroWave2.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n### Format Wave 3\n\n```{r, eval =F}\n# read in cross-stats\n## wave 3\ncrossDir=\"/CCACE_Shared/Anna_F/BrainAtrophy/data\"\ncross = fread(paste0(crossDir, \"/LBC1936_global_w3_cross.csv\"), data.table=F)\nnames(cross) = gsub(\"-\", \".\", names(cross), fixed = T)\n\n# format each of those variables to long format\n## TotalGrayVol\n## Right.Cerebellum.White.Matter\n## Left.Cerebellum.White.Matter\ncrossLBC = cross[ , c(1, grep(\"TotalGrayVol|Right.Cerebellum.White.Matter|Left.Cerebellum.White.Matter|CorticalWhiteMatterVol|CSF|IntraCranialVol\", names(cross))) ]\n# remove lh & rhCorticalWhiteMatterVol (because whole measure is also included)\ncrossLBC = crossLBC[, !grepl(\"rh|lh\", names(crossLBC))]\n\n# calculate sum of the regions\ncrossLBC$TBV = rowSums(crossLBC[,c(\"TotalGrayVol\", \"Right.Cerebellum.White.Matter\", \"Left.Cerebellum.White.Matter\", \"CorticalWhiteMatterVol\")], na.rm = F)\n\n# rename for easier names\nnames(crossLBC)[grep(\"Measure:volume\", names(crossLBC))] = \"lbc36no\"\nnames(crossLBC)[grep(\"IntraCranialVol\", names(crossLBC))] = \"ICV\"\n\ncrossLBC = crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\")]\n\n# no participants have smaller ICV than TBV\n#crossLBC = crossLBC[-which(crossLBC$ICV - crossLBC$TBV <0),]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\ncrossLBC$ICV = crossLBC$ICV/1000\ncrossLBC$TBV = crossLBC$TBV/1000\n\n# estimate brain atrophy from single MRI scan\ncrossLBC$diff = crossLBC$ICV - crossLBC$TBV\ncrossLBC$ratio = crossLBC$TBV / crossLBC$ICV\n\n##### derive the residuals for each time point separately \nmodel <- lm(TBV ~ ICV, data = crossLBC)\ncrossLBC$resid = resid(model)\n\n# standardise variables within one time-point\ncrossLBC$resid_stand = as.vector(scale(crossLBC$resid))\ncrossLBC$diff_stand = as.vector(scale(crossLBC$diff))\ncrossLBC$ratio_stand = as.vector(scale(crossLBC$ratio))\ncrossLBC$TBVstand = as.vector(scale(crossLBC$TBV))\ncrossLBC$ICVstand = as.vector(scale(crossLBC$ICV))\ncrossLBC$CSFstand = as.vector(scale(crossLBC$CSF))\n\n# rename participant labels to match global naming\ncrossLBC$lbc36no = stringr::str_remove(crossLBC$lbc36no, pattern = \"_W3\")\n\n# store as txt file\nfwrite(crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\", \"diff\", \"ratio\", \"resid\", \"ICVstand\", \"TBVstand\", \"CSFstand\", \"resid_stand\", \"diff_stand\", \"ratio_stand\")], paste0(wd, \"/LBC1936_crossNeuroWave3.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n\n### Format Wave 4\n\n```{r, eval =F}\n# read in cross-stats\n## wave 4\ncrossDir=\"/CCACE_Shared/Anna_F/BrainAtrophy/data\"\ncross = fread(paste0(crossDir, \"/LBC1936_global_w4_cross.csv\"), data.table=F)\nnames(cross) = gsub(\"-\", \".\", names(cross), fixed = T)\n\n# format each of those variables to long format\n## TotalGrayVol\n## Right.Cerebellum.White.Matter\n## Left.Cerebellum.White.Matter\ncrossLBC = cross[ , c(1, grep(\"TotalGrayVol|Right.Cerebellum.White.Matter|Left.Cerebellum.White.Matter|CorticalWhiteMatterVol|CSF|IntraCranialVol\", names(cross))) ]\n# remove lh & rhCorticalWhiteMatterVol (because whole measure is also included)\ncrossLBC = crossLBC[, !grepl(\"rh|lh\", names(crossLBC))]\n\n# calculate sum of the regions\ncrossLBC$TBV = rowSums(crossLBC[,c(\"TotalGrayVol\", \"Right.Cerebellum.White.Matter\", \"Left.Cerebellum.White.Matter\", \"CorticalWhiteMatterVol\")], na.rm = F)\n\n# rename for easier names\nnames(crossLBC)[grep(\"Measure:volume\", names(crossLBC))] = \"lbc36no\"\nnames(crossLBC)[grep(\"IntraCranialVol\", names(crossLBC))] = \"ICV\"\n\ncrossLBC = crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\")]\n\n# no participants have smaller ICV than TBV\n#crossLBC = crossLBC[-which(crossLBC$ICV - crossLBC$TBV <0),]\n\n### calculate atrophy measures\n# convert mm3 estimates to more intuitive cm3 estimates\ncrossLBC$ICV = crossLBC$ICV/1000\ncrossLBC$TBV = crossLBC$TBV/1000\n\n# estimate brain atrophy from single MRI scan\ncrossLBC$diff = crossLBC$ICV - crossLBC$TBV\ncrossLBC$ratio = crossLBC$TBV / crossLBC$ICV\n\n##### derive the residuals for each time point separately \nmodel <- lm(TBV ~ ICV, data = crossLBC)\ncrossLBC$resid = resid(model)\n\n# standardise variables within one time-point\ncrossLBC$resid_stand = as.vector(scale(crossLBC$resid))\ncrossLBC$diff_stand = as.vector(scale(crossLBC$diff))\ncrossLBC$ratio_stand = as.vector(scale(crossLBC$ratio))\ncrossLBC$TBVstand = as.vector(scale(crossLBC$TBV))\ncrossLBC$ICVstand = as.vector(scale(crossLBC$ICV))\ncrossLBC$CSFstand = as.vector(scale(crossLBC$CSF))\n\n# rename participant labels to match global naming\ncrossLBC$lbc36no = stringr::str_remove(crossLBC$lbc36no, pattern = \"_W4\")\n\n# store as txt file\nfwrite(crossLBC[,c(\"lbc36no\", \"ICV\", \"TBV\", \"CSF\", \"diff\", \"ratio\", \"resid\", \"ICVstand\", \"TBVstand\", \"CSFstand\", \"resid_stand\", \"diff_stand\", \"ratio_stand\")], paste0(wd, \"/LBC1936_crossNeuroWave4.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n\n### Visualise cross-secional scores (waves 2 and 5)\n\n```{r plot, eval=F}\n# read in LBC neuroimaging data \nLBC2 = fread(paste0(wd, \"/LBC1936_crossNeuroWave1.txt\"))\nLBC2$wave = 2\nLBC5 = fread(paste0(wd, \"/LBC1936_crossNeuroWave4.txt\"))\nLBC5$wave = 5\nLBC = rbind(LBC2, LBC5)\n\np1 = plot_hist(dat = LBC, var = \"diff\", split_sample_by = \"wave\")+\n          xlab(\"ICV - TBV\\n(raw difference score)\")+\n          theme(legend.position=\"none\")+\n          make_pretty()\n# delete SD stats\np1$layers[[2]]=NULL\n\np2 = plot_hist(dat = LBC, var = \"ratio\", split_sample_by = \"wave\")+\n          xlab(\"TBV / ICV\\n(raw ratio score)\")+\n          theme(legend.position=\"none\")+\n          make_pretty()\n# delete SD stats\np2$layers[[2]]=NULL\n\np3 = plot_hist(dat = LBC, var = \"resid\", split_sample_by = \"wave\")+\n          xlab(\"TBV ~ ICV\\n(raw residual score)\")+\n          make_pretty()\n# delete SD stats\np3$layers[[2]]=NULL\n\n# combine plots\nplot = plot_grid(p1, p2, p3, nrow = 1, labels = c(\"A\", \"B\", \"C\"), label_size = 6, rel_widths = c(1,1,1.5))\n# save plot\nggsave(paste0(wd, \"LBCDistributionsCross.jpg\"), plot = plot, width = 12, height = 5, units = \"cm\", dpi = 300)\n```\n\n![Distribution of atrophy scores derived from cross-sectional data](/CCACE_Shared/Anna_F/BrainAtrophy/data/LBCDistributionsCross.jpg)\n\n\n### Descriptive statistics (cross-sectional measures)\n\n```{r descriptives, results='asis', message=F, warning=F, eval = F}\noptions(knitr.kable.NA = \"\")\n\n# calculate descriptives\ndes = descriptives(samples = c(\"LBC2\", \"LBC5\"))\n# cut-offs not needed\ndes = des[-which(des$Statistic == \"Cut off\"),]\n\nknitr::kable(des, col.names = c(\"Stats\",\"LBC (wave 1)\", \"LBC (wave 4)\"))\n```\n\n\n\n## Extract from longitudinal FS processing stream output\n\nLBC1936 provides data that was processed with the longitudinal processing stream.\n\nData from the longitudinal processing stream should be used when we are interested in inter-individual changes across time (i.e., analyses not involving ICV).\n\n```{r LBCatrophy, message= F, warning=F, eval = F}\n# https://onlinelibrary.wiley.com/doi/full/10.1002/hbm.25572\n# this paper defines total brain volume as:\n# GMV (cortical and subcortical shoudl also include cerebellum) + cerebellum WMV + cerebral WMV\n# TotalGrayVol + Cerebellum.White.Matter + CorticalWhiteMatterVol\nint=\"/Brain_Imaging/LBC1936_FS_long/freesurfer_stats\"\nLBC = read.table(paste0(int,\"/freesurfer_stats_long_w2to5.csv\"), header=T, sep=\",\")\n\n# format each of those variables to long format\n## TotalGrayVol\nTotalGray = LBC[,c(1,grep(\"TotalGrayVol\", names(LBC)))]\nTotalGray = reshape2::melt(TotalGray, id = \"lbc36no\", variable = \"wave\")\nnames(TotalGray)[grep(\"value\", names(TotalGray))] = \"TotalGrayVol\"\nTotalGray$wave = as.numeric(str_remove(TotalGray$wave, pattern = \"TotalGrayVol_w\"))\n\n## Right.Cerebellum.White.Matter\nRCerebellumWM = LBC[,c(1,grep(\"Right.Cerebellum.White.Matter\", names(LBC)))]\nRCerebellumWM = reshape2::melt(RCerebellumWM, id = \"lbc36no\", variable = \"wave\")\nnames(RCerebellumWM)[grep(\"value\", names(RCerebellumWM))] = \"Right.Cerebellum.White.Matter\"\nRCerebellumWM$wave = as.numeric(str_remove(RCerebellumWM$wave, pattern = \"Right.Cerebellum.White.Matter_w\"))\n\n## Left.Cerebellum.White.Matter\nLCerebellumWM = LBC[,c(1,grep(\"Left.Cerebellum.White.Matter\", names(LBC)))]\nLCerebellumWM = reshape2::melt(LCerebellumWM, id = \"lbc36no\", variable = \"wave\")\nnames(LCerebellumWM)[grep(\"value\", names(LCerebellumWM))] = \"Left.Cerebellum.White.Matter\"\nLCerebellumWM$wave = as.numeric(str_remove(LCerebellumWM$wave, pattern = \"Left.Cerebellum.White.Matter_w\"))\n\n## CorticalWhiteMatterVol\n# find column names first\ncols = names(LBC)[c(1,grep(\"CorticalWhiteMatterVol\", names(LBC)))]\ncols = cols[-grep(\"rh\", cols)]\ncols = cols[-grep(\"lh\", cols)]\n# subset data\nCorticalWhite = LBC[,cols]\nCorticalWhite = reshape2::melt(CorticalWhite, id = \"lbc36no\", variable = \"wave\")\nnames(CorticalWhite)[grep(\"value\", names(CorticalWhite))] = \"CorticalWhiteMatterVol\"\nCorticalWhite$wave = as.numeric(str_remove(CorticalWhite$wave, pattern = \"CorticalWhiteMatterVol_w\"))\n\n## IntraCranialVol\nIntraCran = LBC[,c(1,grep(\"IntraCranialVol\", names(LBC)))]\nIntraCran = reshape2::melt(IntraCran, id = \"lbc36no\", variable = \"wave\")\nnames(IntraCran)[grep(\"value\", names(IntraCran))] = \"ICV\"\nIntraCran$wave = as.numeric(str_remove(IntraCran$wave, pattern = \"IntraCranialVol_w\"))\n#### only looking at IntraCranVol to see if ICV is stable across time - which it is\n# going forward, I will not use ICV from the longitudinal scans  because it is not suitable for cross-person comparisons - here we can only look at within-person changes of TBV\n# for that reason I am not including IntraCran in the merge list below\n\n#### merge the different variables\nDatList = list(TotalGray, RCerebellumWM, LCerebellumWM, CorticalWhite) \nLBC_merged = Reduce(function(x,y) merge(x, y, by = c(\"lbc36no\", \"wave\"), all = T), DatList)\n# no need for time points 3 and 4 for our study\nLBC_merged = LBC_merged[-which(LBC_merged$wave == 3),]\nLBC_merged = LBC_merged[-which(LBC_merged$wave == 4),]\n# get rid of all missing values because we can't confidently compute TBV if some parts of the equation re missing\nLBC_merged = na.omit(LBC_merged)\n\n# calculate sum of the regions\nLBC_merged$TBV = rowSums(LBC_merged[,c(\"TotalGrayVol\", \"Right.Cerebellum.White.Matter\", \"Left.Cerebellum.White.Matter\", \"CorticalWhiteMatterVol\")], na.rm = F)\n#length(unique(LBC_merged$lbc36no))\n# 460\n\n###### include CSF\n# for the analyses in aim 3.1 we only need CSF at wave 5\nCSF = LBC[,c(1,grep(\"CSF_w5\", names(LBC)), grep(\"CSF_w2\", names(LBC)))]\nCSF = reshape2::melt(CSF, id = \"lbc36no\", variable = \"wave\")\nnames(CSF)[grep(\"value\", names(CSF))] = \"CSF\"\nCSF$wave = as.numeric(str_remove(CSF$wave, pattern = \"CSF_w\"))\n### also realised later that I would not want to include CSF measures from longitudinal processing as it's not comparable between participants - will only use CSF estimates from cross-setional processing\n\n# convert mm3 estimates to more intuitive cm3 estimates\nLBC_merged$TBV = LBC_merged$TBV/1000\n\n# store as txt file\nfwrite(LBC_merged[,c(\"lbc36no\", \"wave\", \"TBV\")], paste0(wd, \"/LBC1936_longTBVWaves2and5.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n\n### Format longitudinal change measures\n\n```{r, eval =F}\n# read in LBC data \nneuro = fread(paste0(wd, \"/LBC1936_longTBVWaves2and5.txt\"), data.table = F)\n# extract longitudinal atrophy from LBC data\n#### Difference score \n# Step 1: change to wide format\ntemp = reshape(neuro, idvar = \"lbc36no\", timevar = \"wave\", direction = \"wide\")\ntemp = temp[,c(\"lbc36no\", \"TBV.2\", \"TBV.5\")]\n\n# Step 2: calculate difference in TBV between wave 2 and wave 5\ntemp$TBVdiff_2to5 = temp$TBV.2 - temp$TBV.5\n\n###### Ratio score\n# Step 2: calculate difference in TBV between wave 2 and wave 5\ntemp$TBVratio_5to2 = temp$TBV.5 / temp$TBV.2\n\n###### Resid score\n# remove missing because results with missing produces weird dimensions\ntemp1 = temp[!is.na(temp$TBV.2),]\ntemp1 = temp1[!is.na(temp1$TBV.5),] \n# Step 2: calculate difference in TBV between wave 2 and wave 5\nmodel = lm(TBV.5 ~ TBV.2, data = temp1)\ntemp1$TBVresid_2to5 = resid(model)\n\n# merge back in with complete temp\ntemp = merge(temp, temp1[,c(\"lbc36no\", \"TBVresid_2to5\")], by = \"lbc36no\", all = T)\n\n# Step 3: merge data back with long data\n# changed my mind about that - keeping long and cross data separate will make it easier to treat them distinctly\n# neuro = merge(neuro, temp[,c(\"lbc36no\", \"TBVdiff_2to5\", \"TBVratio_5to2\", \"TBVresid_2to5\")], by = \"lbc36no\", all = T)\n\n# standardise variables\nneuro = temp\nneuro$TBVdiff_2to5_stand = as.numeric(scale(neuro$TBVdiff_2to5))\nneuro$TBVratio_5to2_stand = as.numeric(scale(neuro$TBVratio_5to2))\nneuro$TBVresid_2to5_stand = as.numeric(scale(neuro$TBVresid_2to5))\n\n# store as txt file\nfwrite(neuro, paste0(wd, \"/LBC1936_longTBVWaves2and5.txt\"), quote = F, col.names = T, sep = \"\\t\")\n```\n\n\n### Visualise longitudinal atrophy scores\n\n\n```{r, eval =F}\n# read in LBC neuroimaging data \nLBC = fread(paste0(wd, \"/LBC1936_longTBVWaves2and5.txt\"), data.table=F)\n\n# get N\nN = sum(!is.na(LBC$TBVresid_2to5))\n\n# for the code to run, I will re-name columns, but this is just to not having to recode the plot_hist function - naming remains separate between cross-sectional and longitudinal variables in the saved data \nLBC$diff = LBC$TBVdiff_2to5\np1 = plot_hist(dat = LBC, var = \"diff\", split_sample_by = NULL)+\n          xlab(\"TBV1 - TBV2\\n(difference score)\")+\n\t\t\tylab(paste0(\"Count (N = \", N, \")\"))+\n          theme(legend.position=\"none\")+\n          make_pretty()\n# delete SD stats\np1$layers[[2]]=NULL\n\nLBC$ratio = LBC$TBVratio_5to2\np2 = plot_hist(dat = LBC, var = \"ratio\", split_sample_by = NULL)+\n          xlab(\"TBV2 / TBV1\\n(ratio score)\")+\n\t\t\tylab(paste0(\"Count (N = \", N, \")\"))+\n          theme(legend.position=\"none\")+\n          make_pretty()\n# delete SD stats\np2$layers[[2]]=NULL\n\nLBC$resid = LBC$TBVresid_2to5\np3 = plot_hist(dat = LBC, var = \"resid\", split_sample_by = NULL)+\n          xlab(\"TBV2 ~ TBV1\\n(residual score)\")+\n\t\t\tylab(paste0(\"Count (N = \", N, \")\"))+\n          make_pretty()\n# delete SD stats\np3$layers[[2]]=NULL\n\n# combine plots\nplot = plot_grid(p1, p2, p3, nrow = 1, labels = c(\"A\", \"B\", \"C\"), label_size = 6, rel_widths = c(1,1,1))\n# save plot\nggsave(paste0(wd, \"LBCDistributionsLong.jpg\"), plot = plot, width = 12, height = 5, units = \"cm\", dpi = 300)\n```\n\n![Atrophy measures in the LBC at two time points]()\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":"html","warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"LBC_neuro.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.1.189","theme":"journal","title":"LBC1936: Neuroimaging data preparation","author":"Anna Elisabeth Furtjes","date":"`r format(Sys.time(), '%d %B %Y')`","doi":"test"},"extensions":{"book":{"multiFile":true}}}}}