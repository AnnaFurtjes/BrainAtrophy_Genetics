---
title: "UK Biobank: Neuroimaging data preparation"
format: 
  html:
    code-fold: true
author: "Anna Elisabeth Furtjes"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html
doi: test
---

------------------------------------------------------------------------

```{r setup, include=F, warning=F, message=F, eval=T}
load("paths.RData")
knitr::opts_knit$set(root.dir = wd)
#quarto::quarto_render(input = "LBC_neuro.qmd", output_file = "LBC_neuro.html")
```

Code displayed here was used to obtain neuroimaging measures: TBV, ICV, LBA (difference, ratio, residual scores).



## UKB: Neuroimaging data 

### Format imaging-derived phenotypes (already tabulated by UKB)

This definition here was done before I had the newest data from the UKB RAP. Aim 4 defines age based on the difference in days between the date of assessment and the birth date with updated data so will use that instead! 
```{r}
# it's aim is to extract neuroimaging data for UKB from the IDP variables 
path="/UK_Biobank_New/Data/Raw_Data/1027_Refresh_Dec_2022/675090"
fileID = list.files(pat=path,pattern="csv")
# read in file
file = fread(paste0(path, "/", fileID))
# file doesnt like column names that start with number and it doesnt like -
names(file) = paste0("f.",names(file))
names(file) = gsub("-", "_", names(file), fixed = T)

# keep ID, 26515 & 26521
Cols = grepl("f.eid|f.26515|26521", names(file))

# select columns of interest
file = file[, ..Cols]

# melt data to get wave column
file = melt(file, id.vars = "f.eid", measure.vars = list(c("f.26515_2.0", "f.26515_3.0"), c("f.26521_2.0", "f.26521_3.0")), value.name = c("f.26515", "f.26521"))

# re-name varibale to wave
names(file)[which(names(file) == "variable")] = "wave"

# add +1 for correct wave
file$wave = as.numeric(file$wave) + 1

# name variables TBV and icv
names(file)[grep("f.26515", names(file))] = "TBV"
names(file)[grep("f.26521", names(file))] = "ICV"

##############################
# also add T1 volumetric scaling factor (field ID 25000) & CSF (field ID: 26527)
path="/UK_Biobank_New/Data/Raw_Data/1027_Refresh_Dec_2022/670476"
fileID = list.files(pat=path,pattern="csv")
# read in file
more = fread(paste0(path, "/", fileID))
# R doesnt like column names that start with number and it doesnt like -
names(more) = paste0("f.",names(more))
names(more) = gsub("-", "_", names(more), fixed = T)

# keep ID, 26515 & 26521
Cols = grepl("f.eid|f.25000|26527", names(more))

# select columns of interest
more = more[, ..Cols]

# melt data to get wave column
more = melt(more, id.vars = "f.eid", measure.vars = list(c("f.25000_2.0", "f.25000_3.0"), c("f.26527_2.0", "f.26527_3.0")), value.name = c("f.25000", "f.26527"))

# re-name varibale to wave
names(more)[which(names(more) == "variable")] = "wave"

# add +1 for correct wave
more$wave = as.numeric(more$wave) + 1

# name variables TBV and icv
names(more)[grep("f.25000", names(more))] = "T1ScalingFactor"
names(more)[grep("f.26527", names(more))] = "CSF"

# merge with other data
file = merge(file, more, by = c("f.eid", "wave"),all = T)
##############################

# Quality control: 
# something must have gone wrong if TBV is larger than ICV - delete
delete = sum(file$ICV - file$TBV < 0, na.rm=T)
print(paste(delete, " people have larger TBV than ICV, and will therefore be removed from the sample.")) #17 participants
file = file[file$ICV - file$TBV >= 0,]

# also a participant has ICV > 5000 which would be 5 times thesize of the smaller brains in the sample - delete 
file = file[file$ICV <= 5000000,]

### calculate atrophy measures
# convert mm3 estimates to more intuitive cm3 estimates
file$ICV = file$ICV/1000
file$TBV = file$TBV/1000

# estimate brain atrophy from single MRI scan
file$diff = file$ICV - file$TBV
file$ratio = file$TBV / file$ICV

##### derive the residuals for each time point separately 
## first wave (named wave 2 in UKB)
file1 = file[which(file$wave == 2),]

model <- lm(TBV ~ ICV, data = file1)
file1$resid = resid(model)

# also derive residual model for scaling factor
# for some reason here we have an issue with missing data, so delete and re-merge
fileNoMiss = file1[!is.na(file1$T1ScalingFactor),]

model <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)
fileNoMiss$residScalingFactor = resid(model)

# merge back in with file
file1 = merge(file1, fileNoMiss[,c("f.eid", "residScalingFactor")], by = "f.eid", all.x=T)

sum(!is.na(fileNoMiss$residScalingFactor))
sum(!is.na(file1$residScalingFactor))

# standardise variables within one time-point
file1$resid_stand = as.vector(scale(file1$resid))
file1$diff_stand = as.vector(scale(file1$diff))
file1$ratio_stand = as.vector(scale(file1$ratio))
file1$TBVstand = as.vector(scale(file1$TBV))
file1$ICVstand = as.vector(scale(file1$ICV))
file1$residScalingFactor_stand = as.vector(scale(file1$residScalingFactor))
file1$CSFstand = as.vector(scale(file1$CSF))

# wave 4
file3 = file[which(file$wave == 3),]
model <- lm(TBV ~ ICV, data = file3)
file3$resid = resid(model)

# also derive residual model for scaling factor
# for some reason here we have an issue with missing data, so delete and re-merge
fileNoMiss = file3[!is.na(file3$T1ScalingFactor),]

model <- lm(TBV ~ T1ScalingFactor, data = fileNoMiss)
fileNoMiss$residScalingFactor = resid(model)

# merge back in with file
file3 = merge(file3, fileNoMiss[,c("f.eid", "residScalingFactor")], by = "f.eid", all.x=T)

sum(!is.na(fileNoMiss$residScalingFactor))
sum(!is.na(file3$residScalingFactor))


# standardise variables within one time-point
file3$resid_stand = as.vector(scale(file3$resid))
file3$diff_stand = as.vector(scale(file3$diff))
file3$ratio_stand = as.vector(scale(file3$ratio))
file3$TBVstand = as.vector(scale(file3$TBV))
file3$ICVstand = as.vector(scale(file3$ICV))
file3$residScalingFactor_stand = as.vector(scale(file3$residScalingFactor))
file3$CSFstand = as.vector(scale(file3$CSF))

#merge the two waves back together
file = rbind(file1, file3)

########## derive age information
path="/UK_Biobank_New/Data/Raw_Data/1027_Refresh_Dec_2022/676893"
fileID = list.files(pat=path,pattern="csv")
# read in file
age = fread(paste0(path, "/", fileID))
# R doesnt like column names that start with number and it doesnt like -
names(age) = paste0("f.",names(age))
names(age) = gsub("-", "_", names(age), fixed = T)

# keep Cols: age when attended assessment center (21003), month of birth (52), month of attending assessment center (55)
Cols = grepl("f.eid|f.21003|f.52", names(age))

# select columns of interest
age = age[, ..Cols]

# hold on to variable 52 until after melting process
var52 = age[, c("f.eid", "f.52_0.0")]

# melt data to get wave column
age = melt(age, id.vars = "f.eid", measure.vars = list(c("f.21003_2.0", "f.21003_3.0")), value.name = c("f.21003"))

# format wave variable
names(age)[which(names(age) == "variable")] = "wave"
age$wave = as.numeric(age$wave) + 1

# merge var52 back in (same value for each participant regardless of wave - birth month doesnt change)
age = merge(age, var52, by = "f.eid")

# simplify by deleting missing values
age = age[!is.na(age$f.21003),]

#### get field ID 55 also 
path="/UK_Biobank_New/Data/Raw_Data/1027_Refresh_Dec_2022/670476"
fileID = list.files(pat=path,pattern="csv")
# read in file
asess = fread(paste0(path, "/", fileID))
# R doesnt like column names that start with number and it doesnt like -
names(asess) = paste0("f.",names(asess))
names(asess) = gsub("-", "_", names(asess), fixed = T)

# keep Cols: month of attending assessment center (55)
Cols = grepl("f.eid|f.55_", names(asess))

# select columns of interest
asess = asess[, ..Cols]

# melt data to get wave column
asess = melt(asess, id.vars = "f.eid", measure.vars = list(c("f.55_2.0", "f.55_3.0")), value.name = c("f.55"))
# format wave variable
names(asess)[which(names(asess) == "variable")] = "wave"
asess$wave = stringr::str_remove(asess$wave, "f.55_")
asess$wave = as.numeric(stringr::str_remove(asess$wave, ".0"))

# merge with age info
age = merge(age, asess, by = c("f.eid","wave"))
#head(age[age$f.eid %in% age$f.eid[duplicated(age$f.eid)],])

# work out more exact age
age$ageMonths = age$f.21003 * 12
age$diff = abs(age$f.55 - age$f.52)
age$age = ifelse(!is.na(age$diff), age$ageMonths + age$diff, age$ageMonths)

#notEmpty=which(!is.na(age$f.21003))
#age = age[notEmpty,]

# merge with file data
file = merge(file, age[,c("f.eid", "age","wave")], by = c("f.eid","wave"), all.x = T)
#head(file[file$f.eid %in% file$f.eid[duplicated(file$f.eid)],])

# for now I will only keep participants that have both measurement points
file = file[file$f.eid %in% file$f.eid[duplicated(file$f.eid)],]

# store as txt file
wd = "/CCACE_Shared/Anna_F/BrainAtrophy/data/"
fwrite(file[,c("f.eid", "wave", "ICV", "TBV", "CSF",  "T1ScalingFactor","diff", "ratio", "resid", "ICVstand", "TBVstand", "CSFstand", "resid_stand", "diff_stand", "ratio_stand", "residScalingFactor_stand", "age")], paste0(wd, "/UKB_crossNeuroWave2_3.txt"), quote = F, col.names = T, sep = "\t")
```

## Get longitudinal estimates from this cross-sectional data (UKB_neuroNoLongProcess)

We had planned to longitudinally process UKB data from the initial and second neuroimaging visit. This however was not possibly due to missing files for all but ~600 participants from field ID ... This was during the time that UKB stopped data downloads and did not provide data from field ... Hence, we must unfortunately work with tabulated data only, even to extract longitudinal estimates of brain change.



```{r}
neuro = fread(paste0(wd, "UKB_crossNeuroWave2_3.txt"))

# make wide format 
temp = reshape(neuro[, c("f.eid", "wave", "TBV")], idvar = "f.eid", timevar = "wave", direction = "wide")

#### Difference score 
# Step 2: calculate difference in TBV between wave 2 and wave 5
temp$TBVdiff_2to3 = temp$TBV.2 - temp$TBV.3

###### Ratio score
# Step 2: calculate difference in TBV between wave 2 and wave 5
temp$TBVratio_3to2 = temp$TBV.3 / temp$TBV.2

###### Resid score
# remove missing because results with missing produces weird dimensions
#temp = temp[!is.na(temp$TBV.2),]
#temp = temp[!is.na(temp$TBV.3),] 
# Step 2: calculate difference in TBV between wave 2 and wave 5
model = lm(TBV.3 ~ TBV.2, data = temp)
temp$TBVresid_2to3 = resid(model)

# standardise variables
temp$TBV.2_stand = scale(temp$TBV.2)
temp$TBV.3_stand = scale(temp$TBV.3)
temp$TBVdiff_2to3_stand = scale(temp$TBVdiff_2to3)
temp$TBVratio_3to2_stand = scale(temp$TBVratio_3to2)
temp$TBVresid_2to3_stand = scale(temp$TBVresid_2to3)

# no need to keep TBV.2 and TBV.3
temp = temp[, c(-2,-3)]

# merge back in with neuro
temp = merge(neuro, temp, by = "f.eid")

# store as txt file
fwrite(temp, paste0(wd, "/UKB_neuroNoLongProcess.txt"), quote = F, col.names = T, sep = "\t")
```


